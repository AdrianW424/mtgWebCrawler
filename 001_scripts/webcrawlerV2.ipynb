{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "from urllib3 import disable_warnings\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disable_warnings(InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200...219\n",
      "220...239\n",
      "240...259\n"
     ]
    }
   ],
   "source": [
    "def __checkForEndOfPages(html, page):\n",
    "    \"\"\"checks if the underlined pagenumber in the @html string is equivilant to the number given as @page\n",
    "\n",
    "    Args:\n",
    "        html (str): html-string containing one page\n",
    "        page (int): page number\n",
    "\n",
    "    Returns:\n",
    "        bool: if the page numbers are the same -> False (not end of Pages). If page numbers are not the same -> True\n",
    "    \"\"\"\n",
    "    return int(BeautifulSoup(html, 'html.parser').find('div', class_='simpleRoundedBoxTitleGreyTall').find('div', class_='pagingcontrols').find('a', style='text-decoration:underline;').contents[0]) != page\n",
    "\n",
    "def __deleteRedundantPages(res, div):\n",
    "    # TODO: improve work -> better use inbuild search function\n",
    "    \"\"\"delete all pages from the end, that are redundant\n",
    "\n",
    "    Args:\n",
    "        res (list of string): list that contains all pages\n",
    "        div (int): amount of pages per iteration\n",
    "\n",
    "    Returns:\n",
    "        list of string: list that contains all pages (now without redundant pages at the end)\n",
    "    \"\"\"\n",
    "    if div == 1:\n",
    "        res = res[:-1]\n",
    "    else:\n",
    "        buf = res[-div:]\n",
    "        res = res[:-div]\n",
    "        \n",
    "        parse_buffer1 = int(BeautifulSoup(buf[-1], 'html.parser').find('div', class_='simpleRoundedBoxTitleGreyTall').find('div', class_='pagingcontrols').find('a', style='text-decoration:underline;').contents[0])\n",
    "        for i in reversed(range(1, div)):\n",
    "            parse_buffer2 = int(BeautifulSoup(buf[i-1], 'html.parser').find('div', class_='simpleRoundedBoxTitleGreyTall').find('div', class_='pagingcontrols').find('a', style='text-decoration:underline;').contents[0])\n",
    "            if parse_buffer1 == parse_buffer2:\n",
    "                buf.pop()\n",
    "                if i == 1 and len(res) > 0:\n",
    "                    if int(BeautifulSoup(buf[i-1], 'html.parser').find('div', class_='simpleRoundedBoxTitleGreyTall').find('div', class_='pagingcontrols').find('a', style='text-decoration:underline;').contents[0]) == int(BeautifulSoup(res[-1], 'html.parser').find('div', class_='simpleRoundedBoxTitleGreyTall').find('div', class_='pagingcontrols').find('a', style='text-decoration:underline;').contents[0]):\n",
    "                        buf.pop()\n",
    "            else:\n",
    "                break\n",
    "            parse_buffer1 = parse_buffer2\n",
    "        res += buf\n",
    "    return res\n",
    "\n",
    "async def fetch(s, url):\n",
    "    async with s.get(f'https://gatherer.wizards.com/Pages/Search/Default.aspx?sort=cn+&page={url}&name=%20[]') as r:\n",
    "        if r.status != 200:\n",
    "            r.raise_for_status()\n",
    "        return await r.text()\n",
    "\n",
    "async def fetch_all(s, pageNum, offset, div):\n",
    "    tasks = []\n",
    "    res = []\n",
    "    end = math.ceil(pageNum/div)\n",
    "    if pageNum != 0:\n",
    "        for i in range(int(offset/div), end + int(offset/div)):\n",
    "            for i2 in range(i*div, (i + 1)*div):\n",
    "                task = asyncio.create_task(fetch(s, i2))\n",
    "                tasks.append(task)\n",
    "            res = await asyncio.gather(*tasks)\n",
    "            print(str(i*div) + \"...\" + str((i+1)*div-1))\n",
    "            if __checkForEndOfPages(res[-1], (i + 1)*div):\n",
    "                res = __deleteRedundantPages(res, div)\n",
    "                break  \n",
    "        if pageNum < len(res):\n",
    "            res = res[:pageNum]\n",
    "    else:\n",
    "        i = int(offset/div)\n",
    "        while 1:\n",
    "            for i2 in range(i*div, (i + 1)*div):\n",
    "                task = asyncio.create_task(fetch(s, i2))\n",
    "                tasks.append(task)\n",
    "            res = await asyncio.gather(*tasks)\n",
    "            print(str(i*div) + \"...\" + str((i+1)*div-1))\n",
    "            if __checkForEndOfPages(res[-1], (i + 1)*div):\n",
    "                res = __deleteRedundantPages(res, div)\n",
    "                break\n",
    "            i += 1\n",
    "    return res\n",
    "\n",
    "async def main(pageNum = 0):\n",
    "    div = 20        # integer\n",
    "    offset = 200      # integer - sollte Vielfaches von div sein - bei div = 10 -> offset = 10 oder = 20 oder ... oder = 250\n",
    "                    # wird als offset = 241 gewählt, so wird intern daraus 240 gemacht, genauso bei offset = 242 oder ... oder 249 ... usw.\n",
    "    if div < 1:\n",
    "        print(\"Div muss >= 1\")\n",
    "    else:\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            htmls = await fetch_all(session, pageNum, offset, div)\n",
    "            #print(htmls)\n",
    "            return htmls\n",
    "\n",
    "#asyncio.run(main())\n",
    "if __name__ == \"__main__\":\n",
    "    htmls = await main(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(htmls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageAndID(card):\n",
    "    data = card.find('td', class_='leftCol').find('a').find('img')['src'][5:]\n",
    "    return \"https://gatherer.wizards.com\" + data, re.search(\"multiverseid=(.*)&\", data).group(1)\n",
    "\n",
    "def getName(card):\n",
    "    return card.find('td', class_='middleCol').find('div', class_='cardInfo').find('span', class_='cardTitle').find('a').contents[0]\n",
    "\n",
    "def getType(card):\n",
    "    return re.sub(' +', ' ', re.sub(r'\\r\\n', \"\", str(card.find('td', class_='middleCol').find('div', class_='cardInfo').find('span', class_='typeLine').contents[0]))).strip().replace(\"—\", \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class csvCreator():\n",
    "    \n",
    "    def __init__(this):\n",
    "        this.__csvCols = []\n",
    "        this.__csvConstruct = []\n",
    "        this.__csv = ''\n",
    "    \n",
    "    def defineCols(this, *params):\n",
    "        this.__csvCols = []\n",
    "        for param in params:\n",
    "            this.__csvCols.append(param)\n",
    "    \n",
    "    def addCard(this, *params):\n",
    "        this.__csvConstruct.append([])\n",
    "        for param in params:\n",
    "            if param[0] == \"int\" or param[0] == \"float\":\n",
    "                this.__csvConstruct[-1].append(param[1])\n",
    "            else:\n",
    "                this.__csvConstruct[-1].append(\"\\\"\" + str(param[1]) + \"\\\"\")\n",
    "    \n",
    "    def getCsv(this):\n",
    "        this.__csv = this.__createRow(this.__csvCols)\n",
    "        for row in this.__csvConstruct:\n",
    "            this.__csv += this.__createRow(row)\n",
    "        return this.__csv\n",
    "    \n",
    "    def __createRow(this, row):\n",
    "        buf = \"\"\n",
    "        for valorem in row:\n",
    "            buf += str(valorem) + \",\"\n",
    "        return buf[:-1] + \"\\n\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csvCreator()\n",
    "csv.defineCols(\"ID\", \"Image-ID\", \"Name\", \"Type\")\n",
    "\n",
    "for html in htmls:\n",
    "    results = BeautifulSoup(html, 'html.parser')\n",
    "    cards = results.find_all('tr', class_=['cardItem evenItem', 'cardItem oddItem'])\n",
    "    #print(i)\n",
    "    for card in cards:\n",
    "        img, id = getImageAndID(card)\n",
    "        csv.addCard((\"int\", id), (\"str\", img), (\"str\", getName(card)), (\"str\", getType(card)))\n",
    "    \n",
    "f = open(\"Lukas.csv\", \"w\")\n",
    "f.write(csv.getCsv())\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fc33baed695a5bb14335e30a3d3eed70e7505dd1711acefe1e2909fc8eedfc84"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
